{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "!pip install openai\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRU36Ji5y-Hn",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730750851856,
          "user_tz": 180,
          "elapsed": 14197,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "5e9cb05c-02a2-426a-8e15-fc79cf16b5a7"
      },
      "id": "aRU36Ji5y-Hn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "Collecting openai\n",
            "  Downloading openai-1.53.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.53.1-py3-none-any.whl (387 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m387.5/387.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (327 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.5/327.5 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.7.0 openai-1.53.1\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCuDXC4607YI",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730750855797,
          "user_tz": 180,
          "elapsed": 3947,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "2e79ca69-224b-4fe9-e2a3-7d70dab2810b"
      },
      "id": "XCuDXC4607YI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.53.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "id": "9QBuf4SxSEvYCScjQLXfv2nM",
      "metadata": {
        "tags": [],
        "id": "9QBuf4SxSEvYCScjQLXfv2nM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730750951847,
          "user_tz": 180,
          "elapsed": 63942,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "5da9d98f-62a5-46ab-cae1-5c9458ac8fa5"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
        "import scipy.stats\n",
        "from typing import Dict, List, Union\n",
        "from tqdm import tqdm\n",
        "from openai import OpenAI\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Configure a API key\n",
        "API_KEY = \"token\"\n",
        "MODEL = \"gpt-4\"\n",
        "\n",
        "class SICKEvaluator:\n",
        "    def __init__(self, model_type: str = \"gpt\", threshold: float = 0.5, api_key: str = None):\n",
        "        self.model_type = model_type\n",
        "        self.threshold = threshold\n",
        "        self.results = {}\n",
        "\n",
        "        # Configuração do cliente OpenAI\n",
        "        self.client = OpenAI(api_key=API_KEY)\n",
        "\n",
        "        self.training_prompt = \"\"\"You are a semantic similarity expert. Analyze the following pairs of sentences\n",
        "        and rate their semantic similarity on a scale from 0 to 1, where:\n",
        "        0: The sentences have completely different meanings\n",
        "        1: The sentences have the same meaning\n",
        "        Format your response as a single number between 0 and 1.\"\"\"\n",
        "\n",
        "    def prepare_prompt(self, sentence_pair: Dict) -> str:\n",
        "        \"\"\"\n",
        "        Prepara o prompt para um par de sentenças\n",
        "        \"\"\"\n",
        "        return f\"\"\"Sentence 1: {sentence_pair['sentence1']}\n",
        "                  Sentence 2: {sentence_pair['sentence2']}\n",
        "                  Rate the semantic similarity (0-1):\"\"\"\n",
        "\n",
        "    def _process_with_gpt(self, batch: List[Dict]) -> List[float]:\n",
        "        \"\"\"\n",
        "        Processa um lote usando GPT API\n",
        "        \"\"\"\n",
        "        try:\n",
        "            responses = []\n",
        "            for pair in batch:\n",
        "                prompt = self.prepare_prompt(pair)\n",
        "                response = self.client.chat.completions.create(\n",
        "                    model=MODEL,\n",
        "                    messages=[\n",
        "                        {\"role\": \"system\", \"content\": self.training_prompt},\n",
        "                        {\"role\": \"user\", \"content\": prompt}\n",
        "                    ],\n",
        "                    temperature=0.3\n",
        "                )\n",
        "                responses.append(float(response.choices[0].message.content.strip()))\n",
        "            return responses\n",
        "        except Exception as e:\n",
        "            print(f\"Erro no processamento GPT: {e}\")\n",
        "            return [np.nan] * len(batch)\n",
        "\n",
        "    def evaluate(self, data: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        Avalia o modelo no conjunto de dados\n",
        "        \"\"\"\n",
        "        all_predictions = []\n",
        "        ground_truth = []\n",
        "\n",
        "        # Processa em lotes\n",
        "        for batch in tqdm(data, desc=\"Processando pares de sentenças\"):\n",
        "            if self.model_type == \"gpt\":\n",
        "                predictions = self._process_with_gpt([batch])\n",
        "            else:\n",
        "                predictions = self._process_with_llama([batch])\n",
        "\n",
        "            all_predictions.extend(predictions)\n",
        "            ground_truth.append(float(batch['Quality#1']))\n",
        "\n",
        "        # Calcula métricas\n",
        "        self.results = self.calculate_metrics(all_predictions, ground_truth)\n",
        "        return self.results\n",
        "\n",
        "    def calculate_metrics(self, predictions: List[float], ground_truth: List[float]) -> Dict:\n",
        "        \"\"\"\n",
        "        Calcula todas as métricas relevantes\n",
        "        \"\"\"\n",
        "        # Remove pares com NaN antes do cálculo\n",
        "        valid_pairs = [(p, t) for p, t in zip(predictions, ground_truth) if not np.isnan(p)]\n",
        "        if not valid_pairs:\n",
        "            return {\n",
        "                'pearson': np.nan,\n",
        "                'spearman': np.nan,\n",
        "                'accuracy': np.nan,\n",
        "                'precision': np.nan,\n",
        "                'confusion_matrix': None\n",
        "            }\n",
        "\n",
        "        pred_clean, true_clean = zip(*valid_pairs)\n",
        "\n",
        "        # Métricas de correlação\n",
        "        pearson = scipy.stats.pearsonr(pred_clean, true_clean)[0]\n",
        "        spearman = scipy.stats.spearmanr(pred_clean, true_clean)[0]\n",
        "\n",
        "        # Converte para classificação binária usando threshold\n",
        "        pred_binary = [1 if p >= self.threshold else 0 for p in pred_clean]\n",
        "        true_binary = [1 if t >= self.threshold else 0 for t in true_clean]\n",
        "\n",
        "        # Métricas de classificação\n",
        "        accuracy = accuracy_score(true_binary, pred_binary)\n",
        "        precision = precision_score(true_binary, pred_binary, average='weighted')\n",
        "        conf_matrix = confusion_matrix(true_binary, pred_binary)\n",
        "\n",
        "        return {\n",
        "            'pearson': pearson,\n",
        "            'spearman': spearman,\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'confusion_matrix': conf_matrix\n",
        "        }\n",
        "\n",
        "    def print_results(self):\n",
        "        \"\"\"\n",
        "        Imprime os resultados de forma organizada\n",
        "        \"\"\"\n",
        "        print(\"\\n=== Resultados da Avaliação ===\")\n",
        "        print(f\"Correlação de Pearson: {self.results['pearson']:.4f}\")\n",
        "        print(f\"Correlação de Spearman: {self.results['spearman']:.4f}\")\n",
        "        print(f\"Acurácia: {self.results['accuracy']:.4f}\")\n",
        "        print(f\"Precisão: {self.results['precision']:.4f}\")\n",
        "        print(\"\\nMatriz de Confusão:\")\n",
        "        print(self.results['confusion_matrix'])\n",
        "\n",
        "def main():\n",
        "    # Configuração de arquivos e tamanho da amostra\n",
        "    NOME_ARQUIVO_TREINAMENTO = \"sick_train.csv\"\n",
        "    NOME_ARQUIVO_TESTE = \"sick_test.csv\"\n",
        "    TAMANHO_AMOSTRA = 100  # Define o tamanho máximo da amostra\n",
        "\n",
        "    # Carrega os dados\n",
        "    try:\n",
        "        df = pd.read_csv(NOME_ARQUIVO_TESTE)\n",
        "        print(f\"Arquivo de teste carregado, total de {len(df)} pares\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Arquivo {NOME_ARQUIVO_TESTE} não encontrado, tentando carregar arquivo de treino\")\n",
        "        try:\n",
        "            df = pd.read_csv(NOME_ARQUIVO_TREINAMENTO)\n",
        "            print(f\"Arquivo de treino carregado, total de {len(df)} pares\")\n",
        "        except FileNotFoundError:\n",
        "            raise FileNotFoundError(\"Nenhum arquivo de dados encontrado\")\n",
        "\n",
        "    # Renomeia as colunas para facilitar o acesso\n",
        "    df.columns = ['Quality', '#1 ID', '#2 ID', '#1 String', '#2 String']\n",
        "\n",
        "    print(\"\\nDistribuição das classes de similaridade:\")\n",
        "    print(df['Quality'].value_counts())\n",
        "\n",
        "    # Amostragem aleatória estratificada\n",
        "    df_sample = df.groupby('Quality').apply(\n",
        "        lambda x: x.sample(min(len(x), max(1, TAMANHO_AMOSTRA // len(df['Quality'].unique()))))\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "    print(f\"\\nTamanho da amostra selecionada: {len(df_sample)} pares\")\n",
        "    print(\"Distribuição das classes na amostra:\")\n",
        "    print(df_sample['Quality'].value_counts())\n",
        "\n",
        "    # Prepara os dados da amostra\n",
        "    data = []\n",
        "    for _, row in df_sample.iterrows():\n",
        "        pair = {\n",
        "            'sentence1': row['#1 String'],\n",
        "            'sentence2': row['#2 String'],\n",
        "            'Quality#1': row['Quality'],\n",
        "            'id1': row['#1 ID'],\n",
        "            'id2': row['#2 ID']\n",
        "        }\n",
        "        data.append(pair)\n",
        "\n",
        "    # Inicializa e executa o avaliador\n",
        "    evaluator = SICKEvaluator(model_type=\"gpt\", threshold=0.5)\n",
        "\n",
        "    # Testa a conexão com a API\n",
        "    try:\n",
        "        test_response = evaluator.client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=[{\"role\": \"user\", \"content\": \"Test\"}]\n",
        "        )\n",
        "        print(\"\\nConexão com API bem sucedida\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nErro na conexão com API: {e}\")\n",
        "        return\n",
        "\n",
        "    # Executa a avaliação\n",
        "    print(\"\\nIniciando avaliação dos pares de sentenças...\")\n",
        "    results = evaluator.evaluate(data)\n",
        "    evaluator.print_results()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo de teste carregado, total de 1332 pares\n",
            "\n",
            "Distribuição das classes de similaridade:\n",
            "Quality\n",
            "1    704\n",
            "0    628\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Tamanho da amostra selecionada: 100 pares\n",
            "Distribuição das classes na amostra:\n",
            "Quality\n",
            "0    50\n",
            "1    50\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-f96228e6e584>:156: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_sample = df.groupby('Quality').apply(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Conexão com API bem sucedida\n",
            "\n",
            "Iniciando avaliação dos pares de sentenças...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processando pares de sentenças: 100%|██████████| 100/100 [01:02<00:00,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Resultados da Avaliação ===\n",
            "Correlação de Pearson: 0.0869\n",
            "Correlação de Spearman: 0.1125\n",
            "Acurácia: 0.5000\n",
            "Precisão: 0.5000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[14 36]\n",
            " [14 36]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install llamaapi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhpY-JfFJkTB",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1733760021597,
          "user_tz": 180,
          "elapsed": 6223,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "81766ccb-9f69-4f01-8e49-7105915982cf"
      },
      "id": "UhpY-JfFJkTB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llamaapi\n",
            "  Downloading llamaapi-0.1.36-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.5 in /usr/local/lib/python3.10/dist-packages (from llamaapi) (3.10.10)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from llamaapi) (1.6.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.27.1 in /usr/local/lib/python3.10/dist-packages (from llamaapi) (2.32.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.27.1->llamaapi) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.27.1->llamaapi) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.27.1->llamaapi) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.27.1->llamaapi) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp<4.0.0,>=3.8.5->llamaapi) (4.12.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.5->llamaapi) (0.2.0)\n",
            "Downloading llamaapi-0.1.36-py3-none-any.whl (4.0 kB)\n",
            "Installing collected packages: llamaapi\n",
            "Successfully installed llamaapi-0.1.36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llamaapi import LlamaAPI\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
        "import scipy.stats\n",
        "from typing import Dict, List, Union\n",
        "from tqdm import tqdm\n",
        "\n",
        "LLAMA_API_TOKEN = \"token\"\n",
        "\n",
        "class LlamaSimilarityEvaluator:\n",
        "    def __init__(self, threshold: float = 0.5):\n",
        "        self.llama = LlamaAPI(LLAMA_API_TOKEN)\n",
        "        self.threshold = threshold\n",
        "        self.results = {}\n",
        "\n",
        "    def prepare_prompt(self, sentence_pair: Dict) -> Dict:\n",
        "        \"\"\"\n",
        "        Prepara o prompt para o formato da Llama API\n",
        "        \"\"\"\n",
        "        return {\n",
        "            \"model\": \"llama3.1-70b\",  # Usando o modelo mais recente e capaz\n",
        "            \"messages\": [\n",
        "                {\"role\": \"system\", \"content\": \"You are a semantic similarity expert. Rate the similarity between sentences on a scale from 0 to 1.\"},\n",
        "                {\"role\": \"user\", \"content\": f\"\"\"Rate the semantic similarity between these sentences:\n",
        "                Sentence 1: {sentence_pair['sentence1']}\n",
        "                Sentence 2: {sentence_pair['sentence2']}\n",
        "\n",
        "                Return only a number between 0 and 1, where:\n",
        "                0: Completely different meanings\n",
        "                1: Identical meanings\"\"\"}\n",
        "            ],\n",
        "            \"stream\": False,\n",
        "            \"temperature\": 0.1  # Baixa temperatura para respostas mais consistentes\n",
        "        }\n",
        "\n",
        "    def process_pair(self, pair: Dict) -> float:\n",
        "        \"\"\"\n",
        "        Processa um par de sentenças usando a Llama API\n",
        "        \"\"\"\n",
        "        try:\n",
        "            api_request = self.prepare_prompt(pair)\n",
        "            response = self.llama.run(api_request)\n",
        "\n",
        "            # Extrai o valor numérico da resposta\n",
        "            similarity = float(response.json()['choices'][0]['message']['content'].strip())\n",
        "            return similarity\n",
        "        except Exception as e:\n",
        "            print(f\"Erro no processamento: {e}\")\n",
        "            return np.nan\n",
        "\n",
        "    def evaluate(self, data: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        Avalia o conjunto de dados\n",
        "        \"\"\"\n",
        "        predictions = []\n",
        "        ground_truth = []\n",
        "\n",
        "        print(\"Processando pares de sentenças...\")\n",
        "        for pair in tqdm(data):\n",
        "            similarity = self.process_pair(pair)\n",
        "            if not np.isnan(similarity):\n",
        "                predictions.append(similarity)\n",
        "                # Normaliza ground truth de [1-4] para [0-1]\n",
        "                gt = (float(pair['Quality#1']) - 1) / 3\n",
        "                ground_truth.append(gt)\n",
        "\n",
        "        self.results = self.calculate_metrics(predictions, ground_truth)\n",
        "        return self.results\n",
        "\n",
        "    def calculate_metrics(self, predictions: List[float], ground_truth: List[float]) -> Dict:\n",
        "        \"\"\"\n",
        "        Calcula métricas de avaliação\n",
        "        \"\"\"\n",
        "        if not predictions or not ground_truth:\n",
        "            return {\n",
        "                'pearson': np.nan,\n",
        "                'spearman': np.nan,\n",
        "                'accuracy': np.nan,\n",
        "                'precision': np.nan,\n",
        "                'confusion_matrix': None\n",
        "            }\n",
        "\n",
        "        # Métricas de correlação\n",
        "        pearson = scipy.stats.pearsonr(predictions, ground_truth)[0]\n",
        "        spearman = scipy.stats.spearmanr(predictions, ground_truth)[0]\n",
        "\n",
        "        # Classificação binária\n",
        "        pred_binary = [1 if p >= self.threshold else 0 for p in predictions]\n",
        "        true_binary = [1 if t >= self.threshold else 0 for t in ground_truth]\n",
        "\n",
        "        # Métricas de classificação\n",
        "        accuracy = accuracy_score(true_binary, pred_binary)\n",
        "        precision = precision_score(true_binary, pred_binary, average='weighted', zero_division=0)\n",
        "        conf_matrix = confusion_matrix(true_binary, pred_binary)\n",
        "\n",
        "        return {\n",
        "            'pearson': pearson,\n",
        "            'spearman': spearman,\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'confusion_matrix': conf_matrix\n",
        "        }\n",
        "\n",
        "    def print_results(self):\n",
        "        \"\"\"\n",
        "        Imprime resultados formatados\n",
        "        \"\"\"\n",
        "        print(\"\\n=== Resultados da Avaliação ===\")\n",
        "        print(f\"Correlação de Pearson: {self.results['pearson']:.4f}\")\n",
        "        print(f\"Correlação de Spearman: {self.results['spearman']:.4f}\")\n",
        "        print(f\"Acurácia: {self.results['accuracy']:.4f}\")\n",
        "        print(f\"Precisão: {self.results['precision']:.4f}\")\n",
        "        print(\"\\nMatriz de Confusão:\")\n",
        "        print(self.results['confusion_matrix'])\n",
        "\n",
        "def load_dataset(filename: str, sample_size: int = None) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Carrega e prepara o dataset\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(filename)\n",
        "    df.columns = ['Quality', '#1 ID', '#2 ID', '#1 String', '#2 String']\n",
        "\n",
        "    if sample_size:\n",
        "        df_sample = df.groupby('Quality', group_keys=False).apply(\n",
        "            lambda x: x.sample(min(len(x), max(1, sample_size // len(df['Quality'].unique()))))\n",
        "        ).reset_index(drop=True)\n",
        "    else:\n",
        "        df_sample = df\n",
        "\n",
        "    print(f\"\\nDistribuição das classes na amostra:\")\n",
        "    print(df_sample['Quality'].value_counts().sort_index())\n",
        "\n",
        "    data = []\n",
        "    for _, row in df_sample.iterrows():\n",
        "        pair = {\n",
        "            'sentence1': row['#1 String'],\n",
        "            'sentence2': row['#2 String'],\n",
        "            'Quality#1': row['Quality'],\n",
        "            'id1': row['#1 ID'],\n",
        "            'id2': row['#2 ID']\n",
        "        }\n",
        "        data.append(pair)\n",
        "\n",
        "    return data\n",
        "\n",
        "def main():\n",
        "    print(\"Iniciando avaliação de similaridade com Llama API...\")\n",
        "\n",
        "    # Carrega dados\n",
        "    try:\n",
        "        data = load_dataset('cohquad_sick_train.csv', sample_size=100)\n",
        "        print(f\"Total de pares carregados: {len(data)}\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"Arquivo de dados não encontrado!\")\n",
        "        return\n",
        "\n",
        "    # Inicializa e executa avaliador\n",
        "    evaluator = LlamaSimilarityEvaluator(threshold=0.5)\n",
        "\n",
        "    # Testa conexão com API\n",
        "    try:\n",
        "        test_request = {\n",
        "            \"model\": \"llama3.1-70b\",\n",
        "            \"messages\": [{\"role\": \"user\", \"content\": \"Test\"}],\n",
        "            \"stream\": False\n",
        "        }\n",
        "        evaluator.llama.run(test_request)\n",
        "        print(\"\\nConexão com Llama API bem sucedida\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nErro na conexão com Llama API: {e}\")\n",
        "        return\n",
        "\n",
        "    # Executa avaliação\n",
        "    print(\"\\nIniciando avaliação dos pares de sentenças...\")\n",
        "    evaluator.evaluate(data)\n",
        "    evaluator.print_results()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "FvY0HM9Iygvo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1733760242874,
          "user_tz": 180,
          "elapsed": 217865,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "54d10682-126c-4f9e-ff57-b98cd45a8273"
      },
      "id": "FvY0HM9Iygvo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando avaliação de similaridade com Llama API...\n",
            "\n",
            "Distribuição das classes na amostra:\n",
            "Quality\n",
            "0    50\n",
            "1    50\n",
            "Name: count, dtype: int64\n",
            "Total de pares carregados: 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-bba650c92ffb>:125: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_sample = df.groupby('Quality', group_keys=False).apply(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Conexão com Llama API bem sucedida\n",
            "\n",
            "Iniciando avaliação dos pares de sentenças...\n",
            "Processando pares de sentenças...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [03:28<00:00,  2.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Resultados da Avaliação ===\n",
            "Correlação de Pearson: 0.1525\n",
            "Correlação de Spearman: 0.1766\n",
            "Acurácia: 0.4400\n",
            "Precisão: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[44 56]\n",
            " [ 0  0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CioEUoWEJh9q"
      },
      "id": "CioEUoWEJh9q",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "SICK_LLM_GPT"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}